<div align="center">
  <h2>ğŸ” Burger Crawler</h2>
  <h3><b><i>"ì§€ì‹ì€ í–„ë²„ê±°ë¥¼ ëŒ€ì‹ í•  ìˆ˜ ì—†ì–´"</i></b></h3>
  <p>í–„ë²„ê±° ì‹ ì œí’ˆ ì •ë³´ë¥¼ ìë™ ìˆ˜ì§‘í•˜ì—¬ Supabaseì— ì €ì¥</p>
</div>

## ğŸš€ Features

- ğŸ•·ï¸ **ë©€í‹° ë¸Œëœë“œ í¬ë¡¤ë§**: ë§¥ë„ë‚ ë“œ, ë²„ê±°í‚¹, ë¡¯ë°ë¦¬ì•„ ë“± ì£¼ìš” ë¸Œëœë“œ
- ğŸ“… **ìë™ ìŠ¤ì¼€ì¤„ë§**: ì •ê¸°ì ìœ¼ë¡œ ì‹ ì œí’ˆ ì •ë³´ ìˆ˜ì§‘
- ğŸ—„ï¸ **Supabase ì—°ë™**: ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ í´ë¼ìš°ë“œ DBì— ì•ˆì „í•˜ê²Œ ì €ì¥
- ğŸ”„ **ì¤‘ë³µ ì œê±°**: ì´ë¯¸ ìˆ˜ì§‘ëœ ì œí’ˆì€ ìë™ìœ¼ë¡œ í•„í„°ë§
- ğŸ“ **ìƒì„¸ ë¡œê¹…**: í¬ë¡¤ë§ ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ìƒì„¸í•˜ê²Œ ê¸°ë¡

## ğŸ› ï¸ Tech Stack

- **Language**: Python 3.8+
- **Database**: Supabase (PostgreSQL)
- **Web Scraping**: Requests, BeautifulSoup4, Selenium
- **Scheduling**: Schedule, APScheduler
- **Logging**: Loguru
- **Environment**: python-dotenv

## ğŸ“¦ Installation

### Windows

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd burger-crawler

# ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
setup.bat
```

### Linux/Mac

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd burger-crawler

# ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x setup.sh
./setup.sh
```

### Manual Setup

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/Scripts/activate  # Windows
# source venv/bin/activate    # Linux/Mac

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ í¸ì§‘
```

## âš™ï¸ Configuration

`.env` íŒŒì¼ì—ì„œ ë‹¤ìŒ ì„¤ì •ì„ í¸ì§‘í•˜ì„¸ìš”:

```env
# Supabase Configuration
SUPABASE_URL=your_supabase_url_here
SUPABASE_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_KEY=your_supabase_service_key_here

# Crawling Settings
HEADLESS_MODE=True
REQUEST_DELAY=1
CRAWL_INTERVAL_HOURS=6
```

## ğŸ—ƒï¸ Database Schema

Supabaseì— ë‹¤ìŒê³¼ ê°™ì€ í…Œì´ë¸” êµ¬ì¡°ê°€ í•„ìš”í•©ë‹ˆë‹¤:

```sql
-- ì¶”í›„ DB ìŠ¤í‚¤ë§ˆë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ì—¬ê¸°ì— ì¶”ê°€
```

## ğŸš€ Usage

### ê¸°ë³¸ ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘)

```bash
python main.py
```

### ëª…ë ¹ì–´ ì˜µì…˜

```bash
# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
python main.py test-db

# íŠ¹ì • ë¸Œëœë“œ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
python main.py test-crawler mcdonalds

# ëª¨ë“  í¬ë¡¤ëŸ¬ í•œ ë²ˆ ì‹¤í–‰
python main.py run-once

# ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
python main.py scheduler
```

## ğŸ•·ï¸ Supported Brands

- ğŸŸ¡ **ë§¥ë„ë‚ ë“œ** (McDonald's)
- ğŸ”´ **ë²„ê±°í‚¹** (Burger King)
- ğŸŸ  **ë¡¯ë°ë¦¬ì•„** (Lotteria)
- ğŸ”µ **KFC** (ì¶”ê°€ ì˜ˆì •)
- ğŸŸ¢ **ë§˜ìŠ¤í„°ì¹˜** (ì¶”ê°€ ì˜ˆì •)

## ğŸ“‚ Project Structure

```
burger-crawler/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crawlers.py      # í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ë“¤
â”‚   â”œâ”€â”€ database.py      # Supabase ì—°ë™
â”‚   â””â”€â”€ scheduler.py     # ìŠ¤ì¼€ì¤„ë§ ë¡œì§
â”œâ”€â”€ logs/                # ë¡œê·¸ íŒŒì¼ë“¤
â”œâ”€â”€ config.py            # ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ main.py              # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
â”œâ”€â”€ requirements.txt     # ì˜ì¡´ì„± íŒ¨í‚¤ì§€
â”œâ”€â”€ .env.example         # í™˜ê²½ ë³€ìˆ˜ ì˜ˆì‹œ
â””â”€â”€ README.md
```

## ğŸ“‹ TODO

- [ ] ì‹¤ì œ ë¸Œëœë“œ ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ë¡œì§ êµ¬í˜„
- [ ] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ ê¸°ëŠ¥
- [ ] ê°€ê²© ë³€ë™ ì¶”ì  ê¸°ëŠ¥
- [ ] ì›¹ ëŒ€ì‹œë³´ë“œ ì¶”ê°€
- [ ] API ì—”ë“œí¬ì¸íŠ¸ ì œê³µ
- [ ] ì•Œë¦¼ ê¸°ëŠ¥ (Discord, Slack ë“±)

## ğŸ¤ Contributing

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ“ Contact

í”„ë¡œì íŠ¸ì— ëŒ€í•œ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
